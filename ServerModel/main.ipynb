{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on colab or locally\n",
    "try:\n",
    "    from google.colab import files\n",
    "    RUNNING_IN_COLAB = True\n",
    "    print(\"Running on Google Colab.\")\n",
    "except ModuleNotFoundError:\n",
    "    RUNNING_IN_COLAB = False\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the git repository from \"https://github.com/valeriodiste/deep_learning_project\" (for the source files)\n",
    "!git clone https://github.com/valeriodiste/macc-project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to the cloned repository\n",
    "%cd /content/macc_project\n",
    "# Pull the latest changes from the repository\n",
    "!git pull origin main\n",
    "# Change the working directory to the parent directory\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "%%capture\n",
    "%pip install 'pytorch-lightning<=2.0.9'\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "REFRESH_DATA = True\n",
    "WANDB_API_KEY = \"2ba6d81dbfe138d5c7fe13aeeeaac296cb88d274\"\n",
    "\n",
    "# Model data parameters\n",
    "NORMALIZE_SENSOR_DATA = True\n",
    "NORMALIZATION_RANGE = [-1, 1]\n",
    "MAX_WEIGHT = 2000\n",
    "MEASUREMENTS = [\n",
    "\t\"accelerometer\",\n",
    "\t# \"deviceTemperature\",\t# Not collected, hence always equal to 0\n",
    "\t\"gravity\",\n",
    "\t\"gyroscope\",\n",
    "\t\"linearAcceleration\",\n",
    "\t# \"orientation\",\t\t# Not collected, hence always equal to <0, 0, 0>\n",
    "\t# \"pressure\",\t\t\t\t# Some devices may not have this sensor, may be always equal to 0\n",
    "\t\"rotationVector\",\n",
    "\t# \"ambientTemperature\"\t# Some devices may not have this sensor, may be always equal to 0\n",
    "]\n",
    "\n",
    "# Model parameters\n",
    "FNN_HIDDEN_DIM = 1024\n",
    "FNN_HIDDEN_LAYERS = 3\n",
    "FNN_ACTIVATION = \"LeakyReLU\"\n",
    "FNN_DROPOUT = 0.5\n",
    "FNN_OPTIMIZER = \"AdamW\"\n",
    "FNN_LR = 0.0000001\n",
    "\n",
    "# Model training parameters\n",
    "DATA_SPLIT = [0.9, 0.075, 0.025]\t# Train, validation, test\n",
    "BATCH_SIZE = 16\n",
    "MAX_EPOCHS = 750\n",
    "\n",
    "# Various paths to save the model\n",
    "if not RUNNING_IN_COLAB:\n",
    "\tmeasurements_dir = \"./measurements\"\n",
    "\tmodel_path = \"./fnn.pth\"\n",
    "\tdata_dir = \"./data\"\n",
    "else:\n",
    "\tmeasurements_dir = \"/content/macc-project/ServerModel/measurements\"\n",
    "\tmodel_path = \"/content/fnn.pth\"\n",
    "\tdata_dir = \"/content/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "# Logger libraries\n",
    "import wandb\n",
    "from wandb.sdk import wandb_run\n",
    "import logging\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "# Torch libraries\n",
    "import torch \n",
    "from torch import nn\n",
    "import pytorch_lightning as pl \n",
    "# Import the fnn module\n",
    "if not RUNNING_IN_COLAB:\n",
    "\tfrom fnn import FNN, ModelData\n",
    "else:\n",
    "\t# Import from \"macc-project.Model.fnn\" (for the source files), using a dash, not an underscore\n",
    "    fnn = __import__(\"macc-project.ServerModel.fnn\", fromlist=[\"fnn\"])\n",
    "    FNN = fnn.FNN\n",
    "    ModelData = fnn.ModelData\n",
    "# Import the tqdm library (for the progress bars)\n",
    "if not RUNNING_IN_COLAB:\n",
    "    from tqdm import tqdm\n",
    "else:\n",
    "    from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Returns the data read from the calibration and measurement files in the corresponding model data directory\n",
    "def get_model_data(refresh=False):\n",
    "\t# Read data from files in the data directory\n",
    "\tcalibration_data = []\n",
    "\tmeasurements_data = []\n",
    "\t# Check if a data directory exists, if it doesn't, create it\n",
    "\tif not os.path.exists(data_dir):\n",
    "\t\tos.makedirs(data_dir)\n",
    "\t# Check if data already exists as \"measurements.json\" and \"calibration.json\" files in the data directory\n",
    "\tif not refresh and os.path.exists(os.path.join(data_dir, \"measurements.json\")) and os.path.exists(os.path.join(data_dir, \"calibration.json\")):\n",
    "\t\t# Read the data from the files\n",
    "\t\twith open(os.path.join(data_dir, \"measurements.json\"), \"r\") as f:\n",
    "\t\t\tmeasurements_data = json.load(f)\n",
    "\t\twith open(os.path.join(data_dir, \"calibration.json\"), \"r\") as f:\n",
    "\t\t\tcalibration_data = json.load(f)\n",
    "\t\treturn calibration_data, measurements_data\n",
    "\telse:\n",
    "\t\t# Build the data dictionaryes, iterating over all files in the directory and getting the corresponding measurements/calibration data\n",
    "\t\tfiles = os.listdir(measurements_dir)\n",
    "\t\tfor file in tqdm(files, desc=\"\\nReading data from files...\",position=0):\n",
    "\t\t\tif file.endswith(\".txt\"):\n",
    "\t\t\t\tis_calibration = file.startswith(\"calibration_\")\n",
    "\t\t\t\tis_measurement = file.startswith(\"measurements_\")\n",
    "\t\t\t\tif not is_calibration and not is_measurement:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tdata_object = {}\n",
    "\t\t\t\twith open(os.path.join(measurements_dir, file), \"r\") as f:\n",
    "\t\t\t\t\tlines = f.readlines()\n",
    "\t\t\t\t\tdata_object[\"sensor_datas\"] = []\n",
    "\t\t\t\t\tfor i in range(len(lines)):\n",
    "\t\t\t\t\t\t# Get the line text\n",
    "\t\t\t\t\t\tline = lines[i]\n",
    "\t\t\t\t\t\tif line == \"\\n\" or line == \"\" or line == \" \":\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\t# Check the line data type\n",
    "\t\t\t\t\t\tif i == 0:\n",
    "\t\t\t\t\t\t\t# Line contains the weight of the measured object\n",
    "\t\t\t\t\t\t\tdata_object[\"weight\"] = float(line)\n",
    "\t\t\t\t\t\telif i == 1:\n",
    "\t\t\t\t\t\t\t# Line contains the name of the corresponding calibration file (as \"calibration_<number>.txt\")\n",
    "\t\t\t\t\t\t\tdata_object[\"calibration_index\"] = int(line.split(\"_\")[1].split(\".\")[0]) - 1\n",
    "\t\t\t\t\t\t\t# data_object[\"calibration_file\"] = line.strip()\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t# Line contains the sensor data\n",
    "\t\t\t\t\t\t\tsensor_measurement_data = {}\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"accelerometer\"] = tuple(map(float, line.split(\";\")[0].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"deviceTemperature\"] = float(line.split(\";\")[1])\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"gravity\"] = tuple(map(float, line.split(\";\")[2].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"gyroscope\"] = tuple(map(float, line.split(\";\")[3].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"linearAcceleration\"] = tuple(map(float, line.split(\";\")[4].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"orientation\"] = tuple(map(float, line.split(\";\")[5].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"pressure\"] = float(line.split(\";\")[6])\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"rotationVector\"] = tuple(map(float, line.split(\";\")[7].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"ambientTemperature\"] = float(line.split(\";\")[8])\n",
    "\t\t\t\t\t\t\tdata_object[\"sensor_datas\"].append(sensor_measurement_data)\n",
    "\t\t\t\t# Add the data object to the corresponding list\n",
    "\t\t\t\tif is_calibration:\n",
    "\t\t\t\t\tcalibration_data.append(data_object)\n",
    "\t\t\t\telif is_measurement:\n",
    "\t\t\t\t\tmeasurements_data.append(data_object)\n",
    "\t\t# Save the data to files\n",
    "\t\twith open(os.path.join(data_dir, \"measurements.json\"), \"w\") as f:\n",
    "\t\t\tjson.dump(measurements_data, f, indent=4)\n",
    "\t\twith open(os.path.join(data_dir, \"calibration.json\"), \"w\") as f:\n",
    "\t\t\tjson.dump(calibration_data, f, indent=4)\n",
    "\t\t# Return the calibration and measurement data\n",
    "\t\treturn calibration_data, measurements_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the random number generator\n",
    "random_seed = 14\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Get the calibration and measurement data\n",
    "print(\"\\nGetting the calibration and measurement data...\")\n",
    "calibration_data, measurements_data = get_model_data(REFRESH_DATA)\n",
    "print(\"> DONE: Data loaded successfully (calibration: \" + str(len(calibration_data)) + \", measurements: \" + str(len(measurements_data)) + \")\")\n",
    "\n",
    "# Define the Weights & Biases logger\n",
    "# Define the wandb logger, api object, entity name and project name\n",
    "wandb_project_name = \"fnn\"\n",
    "wandb_logger = None\n",
    "# wandb_api = None\n",
    "wandb_entity = None\n",
    "wandb_project = None\n",
    "# Check if a W&B api key is provided\n",
    "if WANDB_API_KEY == None or WANDB_API_KEY == \"\":\n",
    "\tprint(\"\\nNo W&B API key provided, logging with W&B disabled.\")\n",
    "elif WANDB_API_KEY != \"\":\n",
    "\t# Login to the W&B (Weights & Biases) API\n",
    "\twandb.login(key=WANDB_API_KEY, relogin=True)\n",
    "\t# Minimize the logging from the W&B (Weights & Biases) library\n",
    "\tos.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\t# os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
    "\tlogging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "\t# Initialize the W&B (Weights & Biases) loggger\n",
    "\twandb_logger = WandbLogger(log_model=\"all\", project=wandb_project_name, name=\"- SEPARATOR -\", offline=False)\n",
    "\t# Initialize the W&B (Weights & Biases) API\n",
    "\t# wandb_api = wandb.Api()\n",
    "\t# Get the W&B (Weights & Biases) entity name\n",
    "\twandb_entity = wandb_logger.experiment.entity\n",
    "\t# Get the W&B (Weights & Biases) project name\n",
    "\twandb_project = wandb_logger.experiment.project\n",
    "\t# Finish the \"separator\" experiment\n",
    "\twandb_logger.experiment.finish(quiet=True)\n",
    "\t# Print the W&B (Weights & Biases) entity and project names, with also the W&B project dashboard URL\n",
    "\tprint(\"\\nW&B API key provided, logging with W&B enabled (entity: \" + wandb_entity + \", project: \" + wandb_project + \")\\n> URL: https://wandb.ai/\" + wandb_entity + \"/\" + wandb_project)\n",
    "\n",
    "# Define the data \n",
    "print(\"\\nInitializing the model data...\")\n",
    "data = ModelData(\n",
    "\tmeasurements_data = measurements_data,\n",
    "\tcalibration_data = calibration_data,\n",
    "\tnormalize_sensor_data = NORMALIZE_SENSOR_DATA,\n",
    "\tnormalization_range = NORMALIZATION_RANGE,\n",
    "\tmax_weight=MAX_WEIGHT,\n",
    "\tdata_split = DATA_SPLIT,\n",
    "\tbatch_size = BATCH_SIZE,\n",
    "\tmeasurement_types = MEASUREMENTS,\n",
    "\tdevice = device\n",
    ")\n",
    "print(\"> DONE: Model data initialized successfully\")\n",
    "\n",
    "# Define the model\n",
    "print(\"\\nInitializing the FNN model...\")\n",
    "model = FNN(\n",
    "\tinput_dim = data.input_dim,\n",
    "\thidden_dim = FNN_HIDDEN_DIM,\n",
    "\thidden_layers = FNN_HIDDEN_LAYERS,\n",
    "\tactivation_fn = FNN_ACTIVATION,\n",
    "\tdropout = FNN_DROPOUT,\n",
    "\toptimizer = FNN_OPTIMIZER,\n",
    "\toutput_dim = 1,\n",
    "\tlr = FNN_LR,\n",
    "\tloss_fn = nn.MSELoss(),\n",
    "\tdevice = device,\n",
    "\tnormalize_data = NORMALIZE_SENSOR_DATA,\n",
    "\tnormalization_range = NORMALIZATION_RANGE,\n",
    "\tmax_weight=MAX_WEIGHT,\n",
    "\tlog_on_wandb = True,\n",
    "\tlog_on_console = False\n",
    ")\n",
    "print(\"> DONE: Model initialized successfully\")\n",
    "\n",
    "# Restore the model from the file (if it exists)\n",
    "# if os.path.exists(model_path):\n",
    "# \tprint(\"\\nRestoring the model from file...\")\n",
    "# \tmodel.load_state_dict(torch.load(model_path))\n",
    "# \tprint(\"> DONE: Model restored successfully\")\n",
    "\n",
    "# Train the model\n",
    "model_wandb_logger = None\n",
    "if wandb_logger != None:\n",
    "\trun_name = \"FNN (\" + str(FNN_HIDDEN_DIM) + \"x\" + str(FNN_HIDDEN_LAYERS) + \" | LR:\" + \"{:.0e}\".format(FNN_LR) + \" | D:\" + str(FNN_DROPOUT) + \" | \" + FNN_OPTIMIZER + \" | \" + FNN_ACTIVATION + \")\"\n",
    "\tmodel_wandb_logger = WandbLogger(log_model=\"all\", project=wandb_project, name=\"FNN\", offline=False)\n",
    "\t# Also save ALL the constants and hyperparameters to the W&B (Weights & Biases) logger, including the data parameters, ecc...\n",
    "\tmodel_wandb_logger.log_hyperparams(\n",
    "\t\t{\n",
    "\t\t\t\"normalize_sensor_data\": NORMALIZE_SENSOR_DATA,\n",
    "\t\t\t\"normalization_range\": NORMALIZATION_RANGE,\n",
    "\t\t\t\"max_weight\": MAX_WEIGHT,\n",
    "\t\t\t\"measurements\": MEASUREMENTS,\n",
    "\t\t\t\"hidden_dim\": FNN_HIDDEN_DIM,\n",
    "\t\t\t\"hidden_layers\": FNN_HIDDEN_LAYERS,\n",
    "\t\t\t\"activation_fn\": FNN_ACTIVATION,\n",
    "\t\t\t\"dropout\": FNN_DROPOUT,\n",
    "\t\t\t\"optimizer\": FNN_OPTIMIZER,\n",
    "\t\t\t\"lr\": FNN_LR,\n",
    "\t\t\t\"data_split\": DATA_SPLIT,\n",
    "\t\t\t\"batch_size\": BATCH_SIZE,\n",
    "\t\t\t\"max_epochs\": MAX_EPOCHS,\n",
    "\t\t\t\"random_seed\": random_seed\n",
    "\t\t}\n",
    "\t)\n",
    "print(\"\\nTraining the model...\")\n",
    "trainer = pl.Trainer(\n",
    "\tmax_epochs=MAX_EPOCHS,\n",
    "\tnum_sanity_val_steps=0,\n",
    "\tlogger=model_wandb_logger,\n",
    "\tlog_every_n_steps=-1,\n",
    "\tenable_checkpointing=False\n",
    ")\n",
    "trainer.fit(model, data)\n",
    "if wandb_logger != None:\n",
    "\t# Finish the \"FNN\" experiment\n",
    "\tmodel_wandb_logger.experiment.finish(quiet=True)\n",
    "print(\"\\n> DONE: Model trained successfully\")\n",
    "\n",
    "# Save model to file (to restore it later)\n",
    "print(\"\\nSaving the model to file...\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Test the model\n",
    "# print(\"\\nTesting the model...\")\n",
    "# trainer.test(model, data.test_dataloader())\n",
    "# print(\"\\n> DONE: Model tested successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

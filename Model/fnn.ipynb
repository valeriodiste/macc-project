{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on colab or locally\n",
    "try:\n",
    "    from google.colab import files\n",
    "    RUNNING_IN_COLAB = True\n",
    "    print(\"Running on Google Colab.\")\n",
    "except ModuleNotFoundError:\n",
    "    RUNNING_IN_COLAB = False\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the git repository from \"https://github.com/valeriodiste/deep_learning_project\" (for the source files)\n",
    "!git clone https://github.com/valeriodiste/macc-project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to the cloned repository\n",
    "%cd /content/macc_project\n",
    "# Pull the latest changes from the repository\n",
    "!git pull origin main\n",
    "# Change the working directory to the parent directory\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Various paths to save the model\n",
    "if not RUNNING_IN_COLAB:\n",
    "\tmeasurements_dir = \"./measurements\"\n",
    "\tmodel_path = \"./fnn.pth\"\n",
    "\tdata_dir = \"./data\"\n",
    "else:\n",
    "\tmeasurements_dir = \"/content/macc_project/Model/measurements\"\n",
    "\tmodel_path = \"/content/macc_project/fnn.pth\"\n",
    "\tdata_dir = \"/content/macc_project/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "import tqdm\n",
    "# Logger libraries\n",
    "import wandb\n",
    "from wandb.sdk import wandb_run\n",
    "import logging\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "# Torch libraries\n",
    "import torch \n",
    "from torch import nn \n",
    "import pytorch_lightning as pl \n",
    "import torch.nn.functional as F \n",
    "# from torchvision import datasets, transforms \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "# For more info: https://www.geeksforgeeks.org/training-neural-networks-using-pytorch-lightning/\n",
    "\n",
    "# Define the model (PyTorch Lightning module, a simple feedforward neural network)\n",
    "# NOTE: model takes as input the sensor data and outputs the weight of the measured object (in grams): don't use CrossEntropyLoss, use MSELoss instead\n",
    "class FNN(pl.LightningModule): \n",
    "\n",
    "\tdef __init__(\n",
    "\t\t\tself,\n",
    "\t\t\t# Required arguments\n",
    "\t\t\tinput_dim: int = 28*28,\n",
    "\t\t\thidden_dim: int = 128,\n",
    "\t\t\thidden_layers: int = 2,\n",
    "\t\t\toutput_dim: int = 10,\n",
    "\t\t\tlr: float = 0.01,\n",
    "\t\t\tloss_fn = nn.MSELoss(),\n",
    "\t\t\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\t\t\t# Optional arguments\n",
    "\t\t\t**kwargs\n",
    "\t\t): \n",
    "\n",
    "\t\tsuper(FNN, self).__init__() \n",
    "\n",
    "\t\t# Define the hyperparameters\n",
    "\t\tself.input_dim = input_dim\n",
    "\t\tself.hidden_dim = hidden_dim\n",
    "\t\tself.hidden_layers = hidden_layers\n",
    "\t\tself.output_dim = output_dim\n",
    "\t\tself.lr = lr\n",
    "\t\tself.loss = loss_fn\n",
    "\t\tself.kwargs = kwargs\n",
    "\t\t# self.device = device\n",
    "\t\t# self.save_hyperparameters()\n",
    "\n",
    "\t\t# Print the final hyperparameters\n",
    "\t\tprint(\"\\nFinal hyperparameters:\")\n",
    "\t\tprint(\"> Input dimension: \", self.input_dim)\n",
    "\t\tprint(\"> Hidden dimension: \", self.hidden_dim)\n",
    "\t\tprint(\"> Hidden layers: \", self.hidden_layers)\n",
    "\t\tprint(\"> Output dimension: \", self.output_dim)\n",
    "\t\tprint(\"> Learning rate: \", self.lr)\n",
    "\t\tprint(\"> Loss function: \", self.loss)\n",
    "\n",
    "\t\t# Define the model architecture\n",
    "\t\tself.layers = []\n",
    "\t\tself.layers.append(nn.Linear(self.input_dim, self.hidden_dim, dtype=torch.float64))\n",
    "\t\tself.layers.append(nn.ReLU())\n",
    "\t\tfor _ in range(self.hidden_layers):\n",
    "\t\t\tself.layers.append(nn.Linear(self.hidden_dim, self.hidden_dim, dtype=torch.float64))\n",
    "\t\t\tself.layers.append(nn.ReLU())\n",
    "\t\tself.layers.append(nn.Linear(self.hidden_dim, self.output_dim, dtype=torch.float64))\n",
    "\t\tself.model = nn.Sequential(*self.layers)\n",
    "\n",
    "\t\t# store variables and lists of losses and accuracies for logging\n",
    "\t\tself.train_losses = []\n",
    "\t\tself.val_losses = []\n",
    "\t\tself.train_accuracies = []\n",
    "\t\tself.val_accuracies = []\n",
    "\t\tself.test_losses = []\n",
    "\t\tself.test_accuracies = []\n",
    "\n",
    "\t# def forward(self, x): \n",
    "\t# \treturn self.model(x)\n",
    "\n",
    "\tdef configure_optimizers(self): \n",
    "\t\toptimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\t\treturn optimizer\n",
    "\t\n",
    "\tdef _step(self, batch, batch_idx):\n",
    "\t\t# Get the data and the target\n",
    "\t\tdata, target = batch\n",
    "\t\t# Forward pass\n",
    "\t\toutput = self.model(data)\n",
    "\t\t# Calculate the loss\n",
    "\t\tloss = self.loss(output, target)\n",
    "\t\t# Calculate the accuracy\n",
    "\t\taccuracy = 1.0 - torch.mean(torch.abs(target - output))\n",
    "\t\t# Return the loss and accuracy\n",
    "\t\treturn loss, accuracy\n",
    "\t\n",
    "\tdef training_step(self, batch, batch_idx):\n",
    "\t\tloss, accuracy = self._step(batch, batch_idx)\n",
    "\t\tself.train_losses.append(loss)\n",
    "\t\tself.train_accuracies.append(accuracy)\n",
    "\t\treturn loss\n",
    "\t\n",
    "\tdef validation_step(self, batch, batch_idx):\n",
    "\t\tloss, accuracy = self._step(batch, batch_idx)\n",
    "\t\tself.val_losses.append(loss)\n",
    "\t\tself.val_accuracies.append(accuracy)\n",
    "\t\treturn loss\n",
    "\t\n",
    "\tdef test_step(self, batch, batch_idx):\n",
    "\t\tloss, accuracy = self._step(batch, batch_idx)\n",
    "\t\tself.test_losses.append(loss)\n",
    "\t\tself.test_accuracies.append(accuracy)\n",
    "\t\treturn loss\n",
    "\t\n",
    "\tdef print_epoch_end(self):\n",
    "\t\tlog_every_n_epochs = 1\n",
    "\t\tepoch = self.current_epoch\n",
    "\t\tif epoch % log_every_n_epochs == 0:\n",
    "\t\t\tif len(self.train_losses)>0 or len(self.train_accuracies)>0 or len(self.val_losses)>0 or len(self.val_accuracies)>0 or len(self.test_losses)>0 or len(self.test_accuracies)>0:\n",
    "\t\t\t\tprint(\"\\nEpoch: \", epoch)\n",
    "\t\t\tif len(self.train_losses)>0:\n",
    "\t\t\t\ttrain_loss = torch.stack(self.train_losses).mean()\n",
    "\t\t\t\ttrain_accuracy = torch.stack(self.train_accuracies).mean()\n",
    "\t\t\t\tself.log(\"train_loss\", train_loss)\n",
    "\t\t\t\tself.log(\"train_accuracy\", train_accuracy)\n",
    "\t\t\t\tprint(\"Train loss: \", round(train_loss.item(), 4), \" | Train accuracy: \", round(train_accuracy.item(), 4))\n",
    "\t\t\tif len(self.val_losses)>0:\n",
    "\t\t\t\tval_loss = torch.stack(self.val_losses).mean()\n",
    "\t\t\t\tval_accuracy = torch.stack(self.val_accuracies).mean()\n",
    "\t\t\t\tself.log(\"val_loss\", val_loss)\n",
    "\t\t\t\tself.log(\"val_accuracy\", val_accuracy)\n",
    "\t\t\t\tprint(\"Validation loss: \", round(val_loss.item(), 4), \" | Validation accuracy: \", round(val_accuracy.item(), 4))\n",
    "\t\t\tif len(self.test_losses)>0:\n",
    "\t\t\t\ttest_loss = torch.stack(self.test_losses).mean()\n",
    "\t\t\t\ttest_accuracy = torch.stack(self.test_accuracies).mean()\n",
    "\t\t\t\tself.log(\"test_loss\", test_loss)\n",
    "\t\t\t\tself.log(\"test_accuracy\", test_accuracy)\n",
    "\t\t\t\tprint(\"Test loss: \", round(test_loss.item(), 4), \" | Test accuracy: \", round(test_accuracy.item(), 4))\n",
    "\t\n",
    "\t# def on_train_epoch_start(self):\n",
    "\t# \tself.train_losses = []\n",
    "\t# \tself.train_accuracies = []\n",
    "\n",
    "\t# def on_train_epoch_end(self):\n",
    "\t# \tepoch = self.current_epoch\n",
    "\t# \tif epoch % 10 == 0:\n",
    "\t# \t\tloss = torch.stack(self.train_losses).mean()\n",
    "\t# \t\taccuracy = torch.stack(self.train_accuracies).mean()\n",
    "\t# \t\tself.log(\"train_loss\", loss)\n",
    "\t# \t\tself.log(\"train_accuracy\", accuracy)\n",
    "\t# \t\tprint(\"\\nTrain loss: \", round(loss.item(), 4), \" | Train accuracy: \", round(accuracy.item(), 4))\n",
    "\n",
    "\t# def on_validation_epoch_start(self):\n",
    "\t# \tself.val_losses = []\n",
    "\t# \tself.val_accuracies = []\n",
    "\n",
    "\t# def on_validation_epoch_end(self):\n",
    "\t# \tepoch = self.current_epoch\n",
    "\t# \tif epoch % 10 == 0:\n",
    "\t# \t\tloss = torch.stack(self.val_losses).mean()\n",
    "\t# \t\taccuracy = torch.stack(self.val_accuracies).mean()\n",
    "\t# \t\tself.log(\"val_loss\", loss)\n",
    "\t# \t\tself.log(\"val_accuracy\", accuracy)\n",
    "\t# \t\tprint(\"\\nValidation loss: \", round(loss.item(), 4), \" | Validation accuracy: \", round(accuracy.item(), 4))\n",
    "\n",
    "\t# def on_test_epoch_start(self):\n",
    "\t# \tself.test_losses = []\n",
    "\t# \tself.test_accuracies = []\n",
    "\n",
    "\t# def on_test_epoch_end(self):\n",
    "\t# \tepoch = self.current_epoch\n",
    "\t# \tif epoch % 10 == 0:\n",
    "\t# \t\tloss = torch.stack(self.test_losses).mean()\n",
    "\t# \t\taccuracy = torch.stack(self.test_accuracies).mean()\n",
    "\t# \t\tself.log(\"test_loss\", loss)\n",
    "\t# \t\tself.log(\"test_accuracy\", accuracy)\n",
    "\t# \t\tprint(\"\\nTest loss: \", round(loss.item(), 4), \" | Test accuracy: \", round(accuracy.item(), 4))\n",
    "\n",
    "\tdef on_train_epoch_start(self):\n",
    "\t\tself.train_losses = []\n",
    "\t\tself.train_accuracies = []\n",
    "\n",
    "\tdef on_validation_epoch_start(self):\n",
    "\t\tself.val_losses = []\n",
    "\t\tself.val_accuracies = []\n",
    "\n",
    "\tdef on_test_epoch_start(self):\n",
    "\t\tself.test_losses = []\n",
    "\t\tself.test_accuracies = []\n",
    "\n",
    "\tdef on_validation_epoch_end(self):\n",
    "\t\tself.print_epoch_end()\n",
    "\n",
    "\tdef on_test_epoch_end(self):\n",
    "\t\tself.print_epoch_end()\n",
    "\n",
    "# Define the data module (PyTorch Lightning DataModule)\n",
    "class ModelData(pl.LightningDataModule): \n",
    "\n",
    "\t# Initialize the data module\n",
    "\tdef __init__(\n",
    "\t\t\tself,\n",
    "\t\t\t# Required arguments\n",
    "\t\t\tmeasurements_data,\n",
    "\t\t\tcalibration_data,\n",
    "\t\t\tmeasurement_types,\n",
    "\t\t\tnormalize_sensor_data,\n",
    "\t\t\tnormalization_range,\n",
    "\t\t\t# Hyperparameters\n",
    "\t\t\tdata_split,\t# Train, validation, test\n",
    "\t\t\tbatch_size,\n",
    "\t\t\tdevice,\n",
    "\t\t\t# Optional arguments\n",
    "\t\t\t**kwargs\n",
    "\t\t): \n",
    "\t\tsuper(ModelData, self).__init__() \n",
    "\t\t# Define the hyperparameters\n",
    "\t\tself.measurements_data = measurements_data\n",
    "\t\tself.calibration_data = calibration_data\n",
    "\t\tself.measurement_types = measurement_types\n",
    "\t\tself.normalize_sensor_data = normalize_sensor_data\n",
    "\t\tself.normalization_range = normalization_range\n",
    "\t\tself.max_weight = 1000\n",
    "\t\tself.data_split = data_split\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.device = device\n",
    "\t\tself.kwargs = kwargs\n",
    "\t\t# Build the data (train, validation, test)\n",
    "\t\tself.train_data, self.val_data, self.test_data = self.get_dataset(self.measurements_data, self.calibration_data, self.measurement_types, self.data_split, self.normalize_sensor_data, self.normalization_range)\n",
    "\t\tself.input_dim = len(self.train_data[0][0])\n",
    "\n",
    "\t# Build the dataset as <sensor_data, weight> pairs where sensor_data contains the calibration data and the measurement data, and weight is the weight of the measured object\n",
    "\tdef get_dataset(self, measurements_data, calibration_data, measurement_types, data_split, normalize_sensor_data, normalization_range):\n",
    "\t\t# Merge the measurements and calibration data into array data\n",
    "\t\tdata = []\n",
    "\t\tfor measurement in measurements_data:\n",
    "\t\t\t# Get the calibration index, sensor data, and weight\n",
    "\t\t\tcalibration_index = measurement[\"calibration_index\"]\n",
    "\t\t\tmeasurement_sensors_data = measurement[\"sensor_datas\"]\n",
    "\t\t\tcalibration_sensor_data = calibration_data[calibration_index][\"sensor_datas\"]\n",
    "\t\t\tweight = measurement[\"weight\"]\n",
    "\t\t\t# Build the data object (normalize all data in the given range if needed)\n",
    "\t\t\tdata_object = []\n",
    "\t\t\tfor i in range(len(measurement_sensors_data)):\n",
    "\t\t\t\tsingle_measurement_sensors_data = measurement_sensors_data[i]\n",
    "\t\t\t\tsingle_calibration_sensor_data = calibration_sensor_data[i]\n",
    "\t\t\t\tfor measurement_type in measurement_types:\n",
    "\t\t\t\t\tif single_measurement_sensors_data[measurement_type] is not None and single_calibration_sensor_data[measurement_type] is not None:\n",
    "\t\t\t\t\t\t# Get the calibration and measurement data\n",
    "\t\t\t\t\t\tcalibration = single_calibration_sensor_data[measurement_type]\n",
    "\t\t\t\t\t\tmeasurement = single_measurement_sensors_data[measurement_type]\n",
    "\t\t\t\t\t\t# Normalize and convert data to tensor (if needed)\n",
    "\t\t\t\t\t\tif normalize_sensor_data:\n",
    "\t\t\t\t\t\t\tif measurement_type == \"accelerometer\":\n",
    "\t\t\t\t\t\t\t\t# Accelerometer is a <x, y, z> tuple with coordinates in m/s^2 (safely assume data is in ranges [-10, 10], normalize to [-1, 1])\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor([val/10.0 for val in calibration], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor([val/10.0 for val in measurement], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telif measurement_type == \"deviceTemperature\":\n",
    "\t\t\t\t\t\t\t\t# Device temperature is a float value in Celsius (safely assume data is in ranges [0, 50], normalize to [-1, 1])\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor([(calibration+50)/100.0], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor([(measurement+50)/100.0], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telif measurement_type == \"gravity\":\n",
    "\t\t\t\t\t\t\t\t# Gravity is a <x, y, z> tuple with coordinates in m/s^2 (safely assume data is in ranges [-10, 10], normalize to [-1, 1], since gravity on Earth is 9.8 m/s^2 on average, never varying by more than 0.2, and can be negative or positive depending on the orientation)\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor([val/10.0 for val in calibration], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor([val/10.0 for val in measurement], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telif measurement_type == \"gyroscope\":\n",
    "\t\t\t\t\t\t\t\t# Gyroscope is a <x, y, z> tuple with coordinates in rad/s (we can assume data to be 360 degrees per second at most, in both directions, normalize to [-1, 1])\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor([val/(2*math.pi) for val in calibration], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor([val/(2*math.pi) for val in measurement], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telif measurement_type == \"linearAcceleration\":\n",
    "\t\t\t\t\t\t\t\t# Linear acceleration is a <x, y, z> tuple with coordinates in m/s^2 (during measurements, acceleration should be small, assume data already in range [-10, 10], normalize to [-1, 1])\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor([val/10.0 for val in calibration], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor([val/10.0 for val in measurement], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telif measurement_type == \"orientation\":\n",
    "\t\t\t\t\t\t\t\t# Orientation is a <x, y, z> tuple with coordinates in degrees (safely assume data is in ranges [-180, 180], normalize to [-1, 1])\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor([val/180.0 for val in calibration], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor([val/180.0 for val in measurement], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telif measurement_type == \"pressure\":\n",
    "\t\t\t\t\t\t\t\t# Pressure is a float value in hPa (safely assume data is in ranges [900, 1100], normalize to [-1, 1])\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor([(calibration-900)/200.0], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor([(measurement-900)/200.0], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telif measurement_type == \"rotationVector\":\n",
    "\t\t\t\t\t\t\t\t# Rotation vector is a <x, y, z> tuple with coordinates in unitless values (safely assume data is in ranges [-1, 1], no need to normalize to [-1, 1])\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor([val for val in calibration], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor([val for val in measurement], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telif measurement_type == \"ambientTemperature\":\n",
    "\t\t\t\t\t\t\t\t# Ambient temperature is a float value in Celsius (safely assume data is in ranges [0, 50], normalize to [-1, 1])\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor([(calibration+50)/100.0], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor([(measurement+50)/100.0], dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t# Throw an error if the measurement type is not recognized\n",
    "\t\t\t\t\t\t\t\traise ValueError(\"Unknown measurement type: \" + measurement_type)\n",
    "\t\t\t\t\t\t\t# Take all data normalized in range [-1,1] and map it to a new range\n",
    "\t\t\t\t\t\t\tcalibration = (calibration - (-1)) * (normalization_range[1] - normalization_range[0]) / (1 - (-1)) + normalization_range[0]\n",
    "\t\t\t\t\t\t\tmeasurement = (measurement - (-1)) * (normalization_range[1] - normalization_range[0]) / (1 - (-1)) + normalization_range[0]\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t# Convert data to tensor (without normalization)\n",
    "\t\t\t\t\t\t\tif type(calibration) == list:\n",
    "\t\t\t\t\t\t\t\tcalibration = torch.tensor(calibration, dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\t\t\tcalibration = torch.tensor(calibration, dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\t\t\traise ValueError(\"Failed to convert calibration data to tensor: \" + str(calibration))\n",
    "\t\t\t\t\t\t\tif type(measurement) == list:\n",
    "\t\t\t\t\t\t\t\tmeasurement = torch.tensor(measurement, dtype=torch.float64)\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\t\t\tmeasurement = torch.tensor(measurement, dtype=torch.float64)\n",
    "\t\t\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\t\t\traise ValueError(\"Failed to convert measurement data to tensor: \" + str(measurement))\n",
    "\t\t\t\t\t\t# Append the data to the data object\n",
    "\t\t\t\t\t\tdata_object.extend(calibration)\n",
    "\t\t\t\t\t\tdata_object.extend(measurement)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t# Throw an error if the data is missing\n",
    "\t\t\t\t\t\traise ValueError(\"Missing data for measurement type: \" + measurement_type)\n",
    "\t\t\t# Append the data object to the data array\n",
    "\t\t\tdata_object = torch.stack(data_object)\n",
    "\t\t\tweight = float(weight)\n",
    "\t\t\t# Normalize and map the weight to the given range (considering a max weight of 1000g) if needed\n",
    "\t\t\tif normalize_sensor_data:\n",
    "\t\t\t\tweight = (weight - 0) * (normalization_range[1] - normalization_range[0]) / (self.max_weight - 0) + normalization_range[0]\n",
    "\t\t\tweight = torch.tensor([weight], dtype=torch.float64)\n",
    "\t\t\tdata.append((data_object, weight))\n",
    "\t\t# Shuffle the data\n",
    "\t\trandom.shuffle(data)\n",
    "\t\t# Define the training and test datasets\n",
    "\t\ttrain_size = int(data_split[0] * len(data))\n",
    "\t\tval_size = int(data_split[1] * len(data))\n",
    "\t\ttest_size = len(data) - train_size - val_size\n",
    "\t\ttrain_data = data[:train_size]\n",
    "\t\tval_data = data[train_size+val_size:]\n",
    "\t\ttest_data = data[train_size:train_size+val_size]\n",
    "\t\treturn train_data, val_data, test_data\n",
    "\t\n",
    "\t# Load the training data\n",
    "\tdef train_dataloader(self): \n",
    "\t\treturn DataLoader(self.train_data, batch_size=self.batch_size)\n",
    "\n",
    "\t# Load the validation data\n",
    "\tdef val_dataloader(self): \n",
    "\t\treturn DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "\t\n",
    "\t# Load the test data\n",
    "\tdef test_dataloader(self): \n",
    "\t\treturn DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "\t\n",
    "\t# Get back the weight from the normalized weight value\n",
    "\tdef get_weight(self, normalized_weight):\n",
    "\t\t# Get the weight from the normalized weight value\n",
    "\t\tweight = (normalized_weight - self.normalization_range[0]) * (self.max_weight - 0) / (self.normalization_range[1] - self.normalization_range[0]) + 0\n",
    "\t\treturn weight\n",
    "\n",
    "# Returns the data read from the calibration and measurement files in the corresponding model data directory\n",
    "def get_model_data(refresh=False):\n",
    "\t# Read data from files in the \"model_data\" directory\n",
    "\t\n",
    "\tcalibration_data = []\n",
    "\tmeasurements_data = []\n",
    "\t# Check if data already exists as \"measurements.json\" and \"calibration.json\" files in the data directory\n",
    "\tif not refresh and os.path.exists(os.path.join(data_dir, \"measurements.json\")) and os.path.exists(os.path.join(data_dir, \"calibration.json\")):\n",
    "\t\t# Read the data from the files\n",
    "\t\twith open(os.path.join(data_dir, \"measurements.json\"), \"r\") as f:\n",
    "\t\t\tmeasurements_data = json.load(f)\n",
    "\t\twith open(os.path.join(data_dir, \"calibration.json\"), \"r\") as f:\n",
    "\t\t\tcalibration_data = json.load(f)\n",
    "\t\treturn calibration_data, measurements_data\n",
    "\telse:\n",
    "\t\t# Build the data dictionaryes, iterating over all files in the directory and getting the corresponding measurements/calibration data\n",
    "\t\tfiles = os.listdir(measurements_dir)\n",
    "\t\tfor file in tqdm.tqdm(files, desc=\"\\nReading data from files...\",position=0):\n",
    "\t\t\tif file.endswith(\".txt\"):\n",
    "\t\t\t\tis_calibration = file.startswith(\"calibration_\")\n",
    "\t\t\t\tis_measurement = file.startswith(\"measurements_\")\n",
    "\t\t\t\tif not is_calibration and not is_measurement:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tdata_object = {}\n",
    "\t\t\t\twith open(os.path.join(measurements_dir, file), \"r\") as f:\n",
    "\t\t\t\t\tlines = f.readlines()\n",
    "\t\t\t\t\tdata_object[\"sensor_datas\"] = []\n",
    "\t\t\t\t\tfor i in range(len(lines)):\n",
    "\t\t\t\t\t\t# Get the line text\n",
    "\t\t\t\t\t\tline = lines[i]\n",
    "\t\t\t\t\t\tif line == \"\\n\" or line == \"\" or line == \" \":\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\t# Check the line data type\n",
    "\t\t\t\t\t\tif i == 0:\n",
    "\t\t\t\t\t\t\t# Line contains the weight of the measured object\n",
    "\t\t\t\t\t\t\tdata_object[\"weight\"] = float(line)\n",
    "\t\t\t\t\t\telif i == 1:\n",
    "\t\t\t\t\t\t\t# Line contains the name of the corresponding calibration file (as \"calibration_<number>.txt\")\n",
    "\t\t\t\t\t\t\tdata_object[\"calibration_index\"] = int(line.split(\"_\")[1].split(\".\")[0]) - 1\n",
    "\t\t\t\t\t\t\t# data_object[\"calibration_file\"] = line.strip()\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t# Line contains the sensor data\n",
    "\t\t\t\t\t\t\tsensor_measurement_data = {}\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"accelerometer\"] = tuple(map(float, line.split(\";\")[0].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"deviceTemperature\"] = float(line.split(\";\")[1])\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"gravity\"] = tuple(map(float, line.split(\";\")[2].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"gyroscope\"] = tuple(map(float, line.split(\";\")[3].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"linearAcceleration\"] = tuple(map(float, line.split(\";\")[4].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"orientation\"] = tuple(map(float, line.split(\";\")[5].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"pressure\"] = float(line.split(\";\")[6])\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"rotationVector\"] = tuple(map(float, line.split(\";\")[7].split(\",\")))\n",
    "\t\t\t\t\t\t\tsensor_measurement_data[\"ambientTemperature\"] = float(line.split(\";\")[8])\n",
    "\t\t\t\t\t\t\tdata_object[\"sensor_datas\"].append(sensor_measurement_data)\n",
    "\t\t\t\t# Add the data object to the corresponding list\n",
    "\t\t\t\tif is_calibration:\n",
    "\t\t\t\t\tcalibration_data.append(data_object)\n",
    "\t\t\t\telif is_measurement:\n",
    "\t\t\t\t\tmeasurements_data.append(data_object)\n",
    "\t\t# Save the data to files\n",
    "\t\twith open(os.path.join(data_dir, \"measurements.json\"), \"w\") as f:\n",
    "\t\t\tjson.dump(measurements_data, f, indent=4)\n",
    "\t\twith open(os.path.join(data_dir, \"calibration.json\"), \"w\") as f:\n",
    "\t\t\tjson.dump(calibration_data, f, indent=4)\n",
    "\t\t# Return the calibration and measurement data\n",
    "\t\treturn calibration_data, measurements_data\n",
    "\n",
    "def main(): \n",
    "\n",
    "\t# General parameters\n",
    "\tREFRESH_DATA = True\n",
    "\tWANDB_API_KEY = \"2ba6d81dbfe138d5c7fe13aeeeaac296cb88d274\"\n",
    "\t# Model data parameters\n",
    "\tNORMALIZE_SENSOR_DATA = True\n",
    "\tNORMALIZATION_RANGE = [-1, 1]\n",
    "\tMEASUREMENTS = [\n",
    "\t\t\"accelerometer\",\n",
    "\t\t# \"deviceTemperature\",\t# Not collected, hence always equal to 0\n",
    "\t\t\"gravity\",\n",
    "\t\t\"gyroscope\",\n",
    "\t\t\"linearAcceleration\",\n",
    "\t\t# \"orientation\",\t\t# Not collected, hence always equal to <0, 0, 0>\n",
    "\t\t# \"pressure\",\t\t\t\t# Some devices may not have this sensor, may be always equal to 0\n",
    "\t\t\"rotationVector\",\n",
    "\t\t# \"ambientTemperature\"\t# Some devices may not have this sensor, may be always equal to 0\n",
    "\t]\n",
    "\t# Model parameters\n",
    "\tFNN_HIDDEN_DIM = 1024\n",
    "\tFNN_HIDDEN_LAYERS = 16\n",
    "\tFNN_LR = 0.00001\n",
    "\t# Model training parameters\n",
    "\tDATA_SPLIT = [0.9, 0.075, 0.025]\t# Train, validation, test\n",
    "\tBATCH_SIZE = 16\n",
    "\tMAX_EPOCHS = 1_000\n",
    "\n",
    "\t# Seed the random number generator\n",
    "\trandom_seed = 14\n",
    "\trandom.seed(random_seed)\n",
    "\ttorch.manual_seed(random_seed)\n",
    "\n",
    "\t# Set the device\n",
    "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\t# Get the calibration and measurement data\n",
    "\tprint(\"\\nGetting the calibration and measurement data...\")\n",
    "\tcalibration_data, measurements_data = get_model_data(REFRESH_DATA)\n",
    "\tprint(\"> DONE: Data loaded successfully (calibration: \" + str(len(calibration_data)) + \", measurements: \" + str(len(measurements_data)) + \")\")\n",
    "\n",
    "\t# Define the Weights & Biases logger\n",
    "\t# Define the wandb logger, api object, entity name and project name\n",
    "\twandb_project_name = \"fnn\"\n",
    "\twandb_logger = None\n",
    "\t# wandb_api = None\n",
    "\twandb_entity = None\n",
    "\twandb_project = None\n",
    "\t# Check if a W&B api key is provided\n",
    "\tif WANDB_API_KEY == None or WANDB_API_KEY == \"\":\n",
    "\t\tprint(\"\\nNo W&B API key provided, logging with W&B disabled.\")\n",
    "\telif WANDB_API_KEY != \"\":\n",
    "\t\t# Login to the W&B (Weights & Biases) API\n",
    "\t\twandb.login(key=WANDB_API_KEY, relogin=True)\n",
    "\t\t# Minimize the logging from the W&B (Weights & Biases) library\n",
    "\t\tos.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\t\tos.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
    "\t\tlogging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
    "\t\t# Initialize the W&B (Weights & Biases) loggger\n",
    "\t\twandb_logger = WandbLogger(log_model=\"all\", project=wandb_project_name, name=\"- SEPARATOR -\", offline=False)\n",
    "\t\t# Initialize the W&B (Weights & Biases) API\n",
    "\t\t# wandb_api = wandb.Api()\n",
    "\t\t# Get the W&B (Weights & Biases) entity name\n",
    "\t\twandb_entity = wandb_logger.experiment.entity\n",
    "\t\t# Get the W&B (Weights & Biases) project name\n",
    "\t\twandb_project = wandb_logger.experiment.project\n",
    "\t\t# Finish the \"separator\" experiment\n",
    "\t\twandb_logger.experiment.finish(quiet=True)\n",
    "\t\t# Print the W&B (Weights & Biases) entity and project names, with also the W&B project dashboard URL\n",
    "\t\tprint(\"\\nW&B API key provided, logging with W&B enabled (entity: \" + wandb_entity + \", project: \" + wandb_project + \")\\n> URL: https://wandb.ai/\" + wandb_entity + \"/\" + wandb_project)\n",
    "\n",
    "\t# Define the data \n",
    "\tprint(\"\\nInitializing the model data...\")\n",
    "\tdata = ModelData(\n",
    "\t\tmeasurements_data = measurements_data,\n",
    "\t\tcalibration_data = calibration_data,\n",
    "\t\tnormalize_sensor_data = NORMALIZE_SENSOR_DATA,\n",
    "\t\tnormalization_range = NORMALIZATION_RANGE,\n",
    "\t\tdata_split = DATA_SPLIT,\n",
    "\t\tbatch_size = BATCH_SIZE,\n",
    "\t\tmeasurement_types = MEASUREMENTS,\n",
    "\t\tdevice = device\n",
    "\t)\n",
    "\tprint(\"> DONE: Model data initialized successfully\")\n",
    "\n",
    "\t# Define the model\n",
    "\tprint(\"\\nInitializing the FNN model...\")\n",
    "\tmodel = FNN(\n",
    "\t\tinput_dim = data.input_dim,\n",
    "\t\thidden_dim = FNN_HIDDEN_DIM,\n",
    "\t\thidden_layers = FNN_HIDDEN_LAYERS,\n",
    "\t\toutput_dim = 1,\n",
    "\t\tlr = FNN_LR,\n",
    "\t\tdevice=device\n",
    "\t)\n",
    "\tprint(\"> DONE: Model initialized successfully\")\n",
    "\n",
    "\t# Restore the model from the file (if it exists)\n",
    "\tif os.path.exists(model_path):\n",
    "\t\tprint(\"\\nRestoring the model from file...\")\n",
    "\t\tmodel.load_state_dict(torch.load(model_path))\n",
    "\t\tprint(\"> DONE: Model restored successfully\")\n",
    "\n",
    "\t# Train the model\n",
    "\tmodel_wandb_logger = None\n",
    "\tif wandb_logger != None:\n",
    "\t\t# Dont save log files locally \n",
    "\t\tmodel_wandb_logger = WandbLogger(log_model=\"all\", project=wandb_project, name=\"FNN\", offline=False)\n",
    "\tprint(\"\\nTraining the model...\")\n",
    "\ttrainer = pl.Trainer(\n",
    "\t\tmax_epochs=MAX_EPOCHS,\n",
    "\t\tnum_sanity_val_steps=0,\n",
    "\t\tlogger=model_wandb_logger,\n",
    "\t\tlog_every_n_steps=-1,\n",
    "\t\tenable_checkpointing=False\n",
    "\t)\n",
    "\ttrainer.fit(model, data)\n",
    "\tif wandb_logger != None:\n",
    "\t\t# Finish the \"FNN\" experiment\n",
    "\t\tmodel_wandb_logger.experiment.finish(quiet=True)\n",
    "\tprint(\"\\n> DONE: Model trained successfully\")\n",
    "\n",
    "\t# Save model to file (to restore it later)\n",
    "\tprint(\"\\nSaving the model to file...\")\n",
    "\ttorch.save(model.state_dict(), model_path)\n",
    "\n",
    "\t# Test the model\n",
    "\t# print(\"\\nTesting the model...\")\n",
    "\t# trainer.test(model, data.test_dataloader())\n",
    "\t# print(\"\\n> DONE: Model tested successfully\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
